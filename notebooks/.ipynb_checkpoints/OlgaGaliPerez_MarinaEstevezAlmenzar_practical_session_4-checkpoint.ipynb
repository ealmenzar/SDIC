{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practical session 4: Modulating internal states and Sensing other robot's attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the last practical session, we saw how to run multiple behaviors in parallel on multiple robots. In this section we will see more advanced methods for combining behaviors by modulating their activations according to internal states of the robot and by allowing them to sense the attributes of others. In order to start with a clean basis, let's first provide the definition of several behaviors. These four behaviors are simply implementations of the [Braitenberg vehicles](https://docs.google.com/presentation/d/1FlAUyvNynYU4mDBE2o20pf2Bn5PC_9Id3SK8sCMfr-Q/edit#slide=id.g31e1b425a3_0_0) we have seen in class, where the sources (i.e. what is sensed by the proximeters) are other epucks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fear(robot):\n",
    "    left, right = robot.prox_activations(tracked_objects=[\"ePuck\"])\n",
    "    left_wheel = left\n",
    "    right_wheel = right\n",
    "    return left_wheel, right_wheel\n",
    "\n",
    "def aggression(robot):\n",
    "    left, right = robot.prox_activations(tracked_objects=[\"ePuck\"])\n",
    "    left_wheel = right\n",
    "    right_wheel = left\n",
    "    return left_wheel, right_wheel\n",
    "\n",
    "def love_cuddly(robot):\n",
    "    left, right = robot.prox_activations(tracked_objects=[\"ePuck\"])\n",
    "    left_wheel = 1 - left\n",
    "    right_wheel = 1 - right   \n",
    "    return left_wheel, right_wheel\n",
    "\n",
    "def love_shy(robot):\n",
    "    left, right = robot.prox_activations(tracked_objects=[\"ePuck\"])\n",
    "    left_wheel = 1 - right\n",
    "    right_wheel = 1 - left   \n",
    "    return left_wheel, right_wheel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the arguments of the behavior functions above are now named `robot`, whereas they were named `epuck`in the previous sessions. This is actually strictly equivalent, the argument name being an arbitrary name. We choose here to call it `robot` in order to avoid a confusion when dealing with multiple epucks. The only important thing is that you use the same name in the function body (i.e `robot` here)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define a fifth behavior for obstacle avoidance, where obstacles are walls, pilars, trees and cups:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obstacle_avoidance(robot):\n",
    "    left, right = robot.prox_activations(tracked_objects=[\"20cm\", \"Tree\", \"Cup\"])\n",
    "    left_wheel = 1 - right\n",
    "    right_wheel = 1 - left   \n",
    "    return left_wheel, right_wheel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open V-REP and load the scene `epuck-scene-4.ttt` located in the directory `sdic2019/pyvrep_epuck/vrep-scenes`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Reminder:** First import the functions `open_session` and `close_session`. Then, obtain a reference to the simulator and the E-Puck by calling `open_session`. Since there are three epucks in the scene, we call it like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from simulator_interface import open_session, close_session\n",
    "simulator, epuck1, epuck2, epuck3 = open_session(n_epucks=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then execute the code you will encounter in the notebook or the code you will write for answering the questions. Whenever you want to restart from scratch (e.g. because something goes wrong or because you want to restart from scratch), first close the session by executing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "close_session(simulator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will properly close all the running processes. Then restart the notebook (`Kernel -> Restart`) and open the session again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "VrepIOErrors",
     "evalue": "Remote error",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mVrepIOErrors\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-c4eb044780fb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msimulator_interface\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mopen_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclose_session\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0msimulator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepuck1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepuck2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepuck3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_epucks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Documents/UPF/Master/2/SDIC/sdic2019/pyvrep_epuck/vrep/simulator.py\u001b[0m in \u001b[0;36mget_session\u001b[0;34m(n_epucks, use_proximeters, old_simulator, old_epuck)\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0msimulator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSimulator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0msimulator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestart_simulation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m     \u001b[0mepucks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0msimulator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_epuck\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muse_proximeters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_proximeters\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_epucks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mn_epucks\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0msimulator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepucks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/UPF/Master/2/SDIC/sdic2019/pyvrep_epuck/vrep/simulator.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0msimulator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSimulator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0msimulator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestart_simulation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m     \u001b[0mepucks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0msimulator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_epuck\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muse_proximeters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_proximeters\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_epucks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mn_epucks\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0msimulator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepucks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/UPF/Master/2/SDIC/sdic2019/pyvrep_epuck/vrep/simulator.py\u001b[0m in \u001b[0;36mget_epuck\u001b[0;34m(self, use_proximeters, verbose)\u001b[0m\n\u001b[1;32m    177\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_epuck\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_proximeters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m         \u001b[0msuffix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_vrep_epuck_suffix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_robots\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m         \u001b[0mepuck\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEpuck\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpypot_io\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mVrepIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvrep_host\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvrep_port\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_robots\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msimulator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrobot_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_robots\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_proximeters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_proximeters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msuffix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msuffix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    180\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msuffix_to_epuck\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msuffix\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepuck\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrobots\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepuck\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/UPF/Master/2/SDIC/sdic2019/pyvrep_epuck/robots/epuck.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, pypot_io, simulator, robot_id, freq, use_proximeters, suffix)\u001b[0m\n\u001b[1;32m     57\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m                 \u001b[0;31m# hide proximeter ray\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhide_ray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0;31m# First calls with simx_opmode_streaming\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/UPF/Master/2/SDIC/sdic2019/pyvrep_epuck/robots/epuck.py\u001b[0m in \u001b[0;36mhide_ray\u001b[0;34m(self, prox_id)\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mhide_ray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprox_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_remote_api\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"simxSetObjectIntParameter\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_all_prox_handles\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mprox_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msending\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdisplay_ray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprox_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/UPF/Master/2/SDIC/sdic2019/pypot/pypot/vrep/io.py\u001b[0m in \u001b[0;36mcall_remote_api\u001b[0;34m(self, func_name, *args, **kwargs)\u001b[0m\n\u001b[1;32m    367\u001b[0m             msg = ' '.join([vrep_error[2 ** i]\n\u001b[1;32m    368\u001b[0m                             for i, e in enumerate(err) if e])\n\u001b[0;32m--> 369\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mVrepIOErrors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    370\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    371\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mVrepIOErrors\u001b[0m: Remote error"
     ]
    }
   ],
   "source": [
    "from simulator_interface import open_session, close_session\n",
    "simulator, epuck1, epuck2, epuck3 = open_session(n_epucks=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And you will restart with a clean session."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Emergent behaviors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When running one or several behaviors on a robot, you might observe behavioral responses that are not present in any of the behavior definitions. This usually doesn't mean that there is a bug, it could just be the result of an emergent behavioral property. Let's analyze this on a quick example, by running the `obstacle_avoidance` behavior on each epuck:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Behavior obstacle_avoidance started\n",
      "Behavior obstacle_avoidance started\n",
      "Behavior obstacle_avoidance started\n"
     ]
    }
   ],
   "source": [
    "for e in simulator.robots:\n",
    "    e.attach_behavior(obstacle_avoidance, freq=10)\n",
    "    e.start_all_behaviors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for e in simulator.robots:\n",
    "    e.detach_all_behaviors()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the cell above is a shortcut to execute the same set of instructions (the indented lines) on all the robots returned by the `open_session` function (the one you use to connect to the simulator). It can become very useful when you want to run the same set of instructions on all the robots, as it is the case here. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q1:** You will observe that the ePucks seem to be attracted to objects that are not handled by the behavior (e.g. other ePucks). Analyse this phenomena and explain below why it is occuring in a few lines:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly, it is important to take into account that all the robots have the same behavior, i.e, the three robots go away from certain obstacles through the same mechanism. Thus, with the obstacle_avoidance behavior each robot can detect certain obstacles such as trees, cups, pillars and walls and go away from them when they are detected. Nevertheless, the robots are not able to detect other robots or obstacles that are not in the list. This means that when a sensor of one robot detects other robots or obstacles that are not in the list, the value of this sensor is null. Therefore, each robot can behave as follows:\n",
    "\n",
    "1. If the left sensor of the robot detects an obstacle from the list and the right sensor detects another robot, the speed of the left wheel will be higher than the speed of the right wheel. This phenomenon promotes that the robot goes away from the obstacle (trees, cups, pillars and walls) and indirectly the robot turns towards the obstacle that is not in the list. The process will be the same with the other sensor.  \n",
    "\n",
    "2. If both sensors detect obstacles that are not in the list (such as another robot), the robot will go forward it since both wheels will have the same velocity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyzing robot interactions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's analyze the interaction between two robots that run different behaviors. First close the current session and open a new one with only two epucks that will be controlled (the third epuck is still part of the scene but we don't need it here):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "close_session(simulator, epuck1, epuck2, epuck3)\n",
    "simulator, epuck1, epuck2 = open_session(n_epucks=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q2:** In addition to the `obstacle_avoidance` behavior, run several combinations of the four other behaviors defined above. For example, run `obstacle_avoidance` and `fear` on `epuck1` ; and `obstacle_avoidance` and `aggression` on `epuck2`. Find two of these combinations that you consider as interesting (e.g. because they result in a relatively complex interaction pattern, or because they can be linked to animal behavior) and describe them in a few lines:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Behavior fear started\n",
      "Behavior obstacle_avoidance started\n",
      "Behavior love_cuddly started\n",
      "Behavior obstacle_avoidance started\n"
     ]
    }
   ],
   "source": [
    "epuck1.attach_behavior(fear, freq=10)\n",
    "epuck2.attach_behavior(love_cuddly, freq=10)\n",
    "\n",
    "for e in simulator.robots:\n",
    "    e.attach_behavior(obstacle_avoidance, freq=10)\n",
    "    e.start_all_behaviors()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The two behaviors we have found interesting in a combination are \"fear behavior\" and \"love_cuddly behavior\", since it seems to be similar to the relation between an animal and its parasite, in the sense that the animal try to avoid the parasite without succesfull, given that the parasite behavior is much more aggresive, so that when the parasite finds the animal, the first follows the latter wherever it goes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for e in simulator.robots:\n",
    "    e.detach_all_behaviors()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weighting behaviors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we have seen in the previous session, it is possible to run several behaviors in parallel on the same robot. When doing it, the motor activation sent to each wheel corresponds to the average of the motor activation returned by each behavior (this averaging is implemented internally, you don't need to worry about it). \n",
    "\n",
    "It is also possible to specify the weight of each running behavior, i.e. how much it will count in the averaging. This is done by returning three values in the function defining a behavior (instead of two as we were doing until now: one for the left wheel activation and one for the right one). For example, if we want to run the `obstacle_avoidance` behavior with a weight of 1 and the `fear` behavior with a weight of 0.5, we write:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Behavior obstacle_avoidance started\n",
      "Behavior fear started\n",
      "Behavior obstacle_avoidance started\n",
      "Behavior fear started\n"
     ]
    }
   ],
   "source": [
    "# First detach all behaviors on both robots:\n",
    "for e in simulator.robots:\n",
    "    e.detach_all_behaviors()\n",
    "    e.stop()\n",
    "    \n",
    "# define the obstacle_avoidance behavior with a weight of 1. This is indicated by the third value returned by the function:\n",
    "def obstacle_avoidance(robot):\n",
    "    left, right = robot.prox_activations(tracked_objects=[\"20cm\", \"Tree\", \"Cup\"])\n",
    "    # The weight associated with this behavior is the third returned value, here 1:\n",
    "    return 1 - right, 1 - left , 1.\n",
    "\n",
    "# define the fear behavior with a weight of 0.5. This is indicated by the third value returned by the function:\n",
    "def fear(robot):\n",
    "    left, right = robot.prox_activations(tracked_objects=[\"ePuck\"])\n",
    "    # The weight associate with this behavior is the third return value, here 0.5:\n",
    "    return left, right, 0.5\n",
    "\n",
    "# Attach and start both behaviors on both robots:\n",
    "for e in simulator.robots:\n",
    "    e.attach_behavior(obstacle_avoidance, freq=10)\n",
    "    e.attach_behavior(fear, freq=10)\n",
    "    e.start_all_behaviors()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By doing this, the wheel activations returned by the `obstacle_avoidance` behavior will have twice more weight than those returned by the `fear` behavior. For example, if `obstacle_avoidance` returns 0.6 for the left wheel, and `fear` returns 0.9, then the total activation of that wheel will be $(0.6 * 1 + 0.9 * 0.5) / (1 + 0.5) = 0.7$ (i.e. the average of both values weighted by their respective activation). Note that when no weight is provided in a behavior definition (i.e. when the behavior function returns only two values as usual), the corresponding behavior is set with a default weight of one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weighting behaviors according to internal states"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This weighting is particularly useful to activate a behavior according to some internal states of the robot. Let's consider a robot that eats spheres (as in the previous session) and that eating those spheres allows to raise a simulated energy level of the robot. We want to continuously compute the energy level of the robot according to how much spheres it has recently eaten. To do so, we first need a way to know when a robot eats a sphere. This is done by executing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epuck1.has_eaten()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cell above return `True` if the robot (`epuck1` here) has eaten a sphere since the last call of the function. Run both the `obstacle avoidance` and the `foraging` behavior on an ePuck and execute the `has_eaten` function above at different times to understand correctly how it works. Remember we have already defined a `foraging_behavior` in the last session, which can be implemented like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def foraging(robot):\n",
    "    left, right = robot.prox_activations(tracked_objects=[\"Sphere\"])\n",
    "    left_activation = right\n",
    "    right_activation = left\n",
    "    return left_activation, right_activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Routine sphere_apparition started\n",
      "Routine eating started\n",
      "Behavior obstacle_avoidance started\n",
      "Behavior foraging started\n",
      "Behavior obstacle_avoidance started\n",
      "Behavior foraging started\n"
     ]
    }
   ],
   "source": [
    "# First start sphere apparition in the environment:\n",
    "simulator.start_sphere_apparition(period=10)\n",
    "\n",
    "# Detach all existing behaviors, and attach then start obstacle_avoidance and foraging on all robots:\n",
    "for e in simulator.robots:\n",
    "    e.detach_all_behaviors()\n",
    "    \n",
    "    e.attach_behavior(obstacle_avoidance, freq=10)\n",
    "    e.attach_behavior(foraging, freq=10)\n",
    "    e.start_all_behaviors()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epuck2.has_eaten()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we want to continuously compute the energy level of a robot, so that the level decreases slowly when nothing is eaten and increases whenever food is consumed. This can be done by attaching and starting a *routine* to a robot. The definition of a routine is very similar to the definition of a behavior, except that it doesn't return any value (whereas a behavior always returns the left and right wheel activations, and optionally a weight). Thus, a routine corresponds to a set of instructions that are executed at a particular frequency (as in a behavior), e.g. to compute some robot's internal states according to its interaction with the environment.\n",
    "\n",
    "Let's define a routine called `foraging_drive` that computes the energy level as specified above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def foraging_drive(robot): \n",
    "    if robot.has_eaten():\n",
    "        robot.energy_level += 0.2  # if the robot has eaten a sphere, increase its energy level by 0.2\n",
    "    else:\n",
    "        robot.energy_level -= 0.01  # otherwise (nothing eaten), decrease the energy level by 0.01\n",
    "    # The line below bounds the value of the energy level between 0 and 1\n",
    "    robot.energy_level = min(1., max(robot.energy_level, 0.))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As for a behavior, the function defining a routine takes a `robot` as an argument representing the ePuck on which the routine is attached. Attaching a routine is done with: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "epuck1.attach_routine(foraging_drive, freq=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As for a behavior, a routine is attached to an epuck at a given frequency. However, contrary to behaviors, routines are not directly involved in motor control and therefore can be run at a lower frequency (1Hz above). The code of the `foraging_drive` function above will be executed each second (1Hz frequency), consequently modulating the ePuck energy level stored in `robot.energy_level` according to how good the robot is at catching spheres.\n",
    "\n",
    "Before starting a routine, we need to define an initial level of energy. Let's do it on `epuck1`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "epuck1.energy_level = 0.5  # Note that the energy level is bounded between 0 and 1 in the foraging_drive function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is mandatory because `energy_level` is incremented or decremented in the `foraging_drive` definition. If not initialized, it will throw an error.\n",
    "\n",
    "Let's now effectively start this routine:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Routine foraging_drive started\n"
     ]
    }
   ],
   "source": [
    "epuck1.start_routine(foraging_drive)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And check the evolution of the energy level in `epuck_1`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "print(epuck1.energy_level)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let the robot behave in the environment and re-execute the cell above to track the evolution of the energy level."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q3:** Modify the `foraging` behavior so that it is weighted according to the energy level of the robot: the lower the energy level, the higher `foraging` is weighted. However, as seen in Q1 above, the ePuck might still be attracted to spheres even when the `foraging` weight is null. Solve this issue by adding another behavior that drives the robot away from sphere according to the energy level: the higher the energy level, the more the robot is repulsed from spheres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Routine sphere_apparition started\n",
      "Routine eating started\n",
      "Behavior obstacle_avoidance started\n",
      "Behavior foraging started\n",
      "Behavior away_from_spheres started\n",
      "Behavior obstacle_avoidance started\n",
      "Behavior foraging started\n",
      "Behavior away_from_spheres started\n",
      "Behavior obstacle_avoidance started\n",
      "Behavior foraging started\n",
      "Behavior away_from_spheres started\n"
     ]
    }
   ],
   "source": [
    "def foraging(robot):\n",
    "    left, right = robot.prox_activations(tracked_objects=[\"Sphere\"])\n",
    "    left_activation = right\n",
    "    right_activation = left\n",
    "    return left_activation, right_activation, 1 - epuck1.energy_level\n",
    "\n",
    "def away_from_spheres(robot):\n",
    "    left, right = robot.prox_activations(tracked_objects=[\"Sphere\"])\n",
    "    left_activation = left\n",
    "    right_activation = right\n",
    "    return left_activation, right_activation, epuck1.energy_level\n",
    "\n",
    "# First start sphere apparition in the environment:\n",
    "simulator.start_sphere_apparition(period=10)\n",
    "\n",
    "# Detach all existing behaviors, and attach then start obstacle_avoidance and foraging on all robots:\n",
    "for e in simulator.robots:\n",
    "    e.detach_all_behaviors()\n",
    "    \n",
    "    e.attach_behavior(obstacle_avoidance, freq=10)\n",
    "    e.attach_behavior(foraging, freq=10)\n",
    "    e.attach_behavior(away_from_spheres, freq=10)\n",
    "    e.start_all_behaviors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for e in simulator.robots:\n",
    "    e.detach_all_behaviors()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sensing other robot's attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can be useful to allow a robot to sense attributes from other robots. For example, one might want to define different species of robot (cats and mouses for example) so that how a robot interact with another depends on their respective species. To achieve this, it is **not** recommended to modify the ePuck labels directly in V-REP (as a general rule, never modify the object labels in the VREP scene). Instead, each robot can be set with a specific attribute, e.g `epuck.species = \"cat\"` and that attribute can be sensed by other robots whenever it is detected by a proximeter. Let's try it with three epucks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "close_session(simulator)\n",
    "simulator, epuck1, epuck2, epuck3 = open_session(n_epucks=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where we define a `species` attribute for each robot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "epuck1.species = \"cat\"\n",
    "epuck2.species = \"mouse\"\n",
    "epuck3.species = \"mouse\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we have one cat and two mouses. Place the robots so that `epuck3` (mouse) is sensing `epuck1` (cat) on its left proximeter and `epuck2` (mouse) on its right proximeter. One can access attributes of sensed epucks by first executing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "(left, right), (epuck_left, epuck_right) = epuck3.prox_activations(tracked_objects=[\"ePuck\"], return_epucks=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This cell above calls the `prox_activations` function of `epuck3` with an additional argument, `return_epucks`, which is set to `True`. When called like this, `prox_activations` will return the left and right proximeter activations as usual, as well as the references to the epucks that are sensed by the proximeters, if any. Then we can access a specific attribute of those ePucks by executing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "none\n",
      "none\n"
     ]
    }
   ],
   "source": [
    "left_species, right_species = epuck3.sensed_epuck_attributes(epuck_left, epuck_right, \"species\", default_value=\"none\")\n",
    "\n",
    "print(left_species)\n",
    "print(right_species)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `sensed_epuck_attributes` function takes 4 arguments: the epuck sensed by the left proximeter (called `epuck_left` in the example above), the one sensed by the right proximeter (called `epuck_right` above), the name of the attribute we are interested in (here `\"species\"`) and the default value to return if a proximeter is not sensing any ePuck (here `none`).\n",
    "\n",
    "Move the robots in the scene and check how the attribute sensing is changing accordingly by re-executing the two above cells. Then try with other attributes, for example by setting a `age` attribute to the robots and sensing it from the proximeters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "epuck1.age = \"10\"\n",
    "epuck2.age = \"15\"\n",
    "epuck3.age = \"25\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "15\n"
     ]
    }
   ],
   "source": [
    "(left, right), (epuck_left, epuck_right) = epuck3.prox_activations(tracked_objects=[\"ePuck\"], return_epucks=True)\n",
    "left_age, right_age = epuck3.sensed_epuck_attributes(epuck_left, epuck_right, \"age\", default_value=\"none\")\n",
    "\n",
    "print(left_age)\n",
    "print(right_age)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now extend the `fear` behavior so that mouses are only afraid by the cat but not by the other mouse:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fear(robot):\n",
    "    # call prox_activation with return_epucks set to True:\n",
    "    (left, right), (epuck_left, epuck_right) = robot.prox_activations(tracked_objects=[\"ePuck\"], return_epucks=True)\n",
    "    # Retrieve the species attributes of the sensed epucks:\n",
    "    left_species, right_species = robot.sensed_epuck_attributes(epuck_left, epuck_right, \"species\", default_value =\"none\")\n",
    "    # Set the left wheel activation to the value of the left sensor if a cat is on the left. Otherwise set it to 0:\n",
    "    left_activation = left if left_species == \"cat\" else 0\n",
    "    # Set the right wheel activation to the value of the right sensor if a cat is on the right. Otherwise set it to 0:\n",
    "    right_activation = right if right_species == \"cat\" else 0\n",
    "    # Return both wheel activation as usual:\n",
    "    return left_activation, right_activation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And run this behavior together with the `obstacle_avoidance` one on `epuck3`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Behavior obstacle_avoidance started\n",
      "Behavior fear started\n"
     ]
    }
   ],
   "source": [
    "epuck3.behavior_mixer.set_mode(\"average\")\n",
    "epuck3.detach_all_behaviors()\n",
    "epuck3.attach_behavior(obstacle_avoidance, freq=10)\n",
    "epuck3.attach_behavior(fear, freq=10)\n",
    "epuck3.start_all_behaviors()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check in the simulator that `epuck3` (mouse) is now avoiding `epuck1` (cat) but not `epuck2` (mouse). We can modify the `species` attribute of robots on the fly. Let's swap the species of `epuck1` and `epuck2`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "epuck1.species = \"mouse\"\n",
    "epuck2.species = \"cat\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check in the simulator that `epuck3` (mouse) is now avoiding `epuck2` (cat) but not `epuck1` (mouse)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q4:** Use the new functionalities we have seen in this session to design the following system:\n",
    "Two epucks are equipped with behaviors to avoid obstacle and catch spheres, as well as being attracted or repulsed by the other epuck. Attraction and repulsion depend on the energy level of the other robot: the higher this level the more attraction, the lower this level the more repulsion. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "for e in simulator.robots:\n",
    "    e.detach_all_behaviors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Routine sphere_apparition started\n",
      "Routine eating started\n",
      "Routine foraging_drive started\n",
      "Behavior obstacle_avoidance started\n",
      "Behavior foraging started\n",
      "Behavior epuck_attraction_repulsion started\n",
      "Routine foraging_drive started\n",
      "Behavior obstacle_avoidance started\n",
      "Behavior foraging started\n",
      "Behavior epuck_attraction_repulsion started\n"
     ]
    }
   ],
   "source": [
    "from simulator_interface import open_session, close_session\n",
    "simulator, epuck1, epuck2 = open_session(n_epucks=2)\n",
    "\n",
    "\n",
    "def foraging(robot):\n",
    "    left, right = robot.prox_activations(tracked_objects=[\"Sphere\"])\n",
    "    left_activation = right\n",
    "    right_activation = left\n",
    "    return left_activation, right_activation\n",
    "\n",
    "\n",
    "def obstacle_avoidance(robot):\n",
    "    left, right = robot.prox_activations(tracked_objects=[\"20cm\", \"Tree\", \"Cup\"])\n",
    "    return 1 - right, 1 - left\n",
    "\n",
    "'''\n",
    "This epuck_attraction_repulsion function describes the energy dependency of attraction and repulsion behavior.\n",
    "When the robot detects another robot with a high level of energy, the behavior turns into attraction,\n",
    "and when the robot detects a robot with a low level of energy, the behavior turns into repulsion:\n",
    "\n",
    "    - If the sensor X (being X \"left\" or \"right\") detects a robot with a high level of energy, \n",
    "    the X_activation value decreases, so the X wheel velocity decreases, and it turns into an \n",
    "    attraction behavior towards this detected robot.\n",
    "    \n",
    "    - In the same way, if the sensor X (being X \"left\" or \"right\") detects a robot with a low level \n",
    "    of energy, the X_activation value increases, so the X wheel velocity increases, and it turns into a \n",
    "    repulsion behavior towards this detected robot.\n",
    "'''\n",
    "def epuck_attraction_repulsion(robot):\n",
    "    left, right = robot.prox_activations(tracked_objects=[\"ePuck\"])\n",
    "    (left, right), (epuck_left, epuck_right) = robot.prox_activations(tracked_objects=[\"ePuck\"], return_epucks=True)\n",
    "    left_energy, right_energy = robot.sensed_epuck_attributes(epuck_left, epuck_right, \"energy_level\", default_value=0)\n",
    "    \n",
    "    left_activation = 1 - left_energy \n",
    "    right_activation = 1 - right_energy\n",
    "    \n",
    "    return left_activation, right_activation\n",
    "\n",
    "\n",
    "def foraging_drive(robot): \n",
    "    if robot.has_eaten():\n",
    "        robot.energy_level += 0.2  # if the robot has eaten a sphere, increase its energy level by 0.2\n",
    "    else:\n",
    "        robot.energy_level -= 0.01  # otherwise (nothing eaten), decrease the energy level by 0.01\n",
    "    # The line below bounds the value of the energy level between 0 and 1\n",
    "    robot.energy_level = min(1., max(robot.energy_level, 0.))\n",
    "\n",
    "    \n",
    "simulator.start_sphere_apparition(period=5)\n",
    "for e in simulator.robots: \n",
    "    e.detach_all_behaviors()\n",
    "    e.attach_routine(foraging_drive, freq=1)\n",
    "    e.energy_level = 0.5\n",
    "    e.start_routine(foraging_drive)\n",
    "    e.attach_behavior(obstacle_avoidance, freq=10)\n",
    "    e.attach_behavior(foraging, freq=10)\n",
    "    e.attach_behavior(epuck_attraction_repulsion, freq=10)\n",
    "    e.start_all_behaviors()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Routine sphere_apparition stopped\n",
      "Routine eating stopped\n"
     ]
    }
   ],
   "source": [
    "for e in simulator.robots: \n",
    "    e.detach_all_behaviors()\n",
    "simulator.stop_sphere_apparition()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q5**: Modify the previous simulation such that attraction and repulsion depend on how much a robot has been close to others in the recent past. To do so, define a `social_drive` routine that modulates the value of a `social_need` attribute in each robot. This social need continuously increases when other robots are far and decreases when a robot comes closer to its conspecifics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Routine sphere_apparition started\n",
      "Routine eating started\n",
      "Routine foraging_drive started\n",
      "Routine social_drive started\n",
      "Behavior obstacle_avoidance started\n",
      "Behavior foraging started\n",
      "Behavior epuck_attraction_repulsion_social started\n",
      "Routine foraging_drive started\n",
      "Routine social_drive started\n",
      "Behavior obstacle_avoidance started\n",
      "Behavior foraging started\n",
      "Behavior epuck_attraction_repulsion_social started\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "This social_drive routine modulates a robot's level of social need. When the robot detects another robot\n",
    "with one of the sensors, or with both, the value of social_need variable decreases. When the robot doesn't\n",
    "detects another robot with any of the sensors, the value of social_need variable increases.\n",
    "'''\n",
    "\n",
    "def social_drive(robot): \n",
    "    left, right = robot.prox_activations(tracked_objects=[\"ePuck\"])\n",
    "    close = left + right\n",
    "    if close > 0.0:\n",
    "        robot.social_need -= 0.05  \n",
    "    else:\n",
    "        robot.social_need += 0.05\n",
    "    robot.social_need = min(1., max(robot.social_need, 0.))\n",
    "   \n",
    "'''\n",
    "This epuck_attraction_repulsion_social function describes the social dependency of attraction and repulsion \n",
    "behavior. When the robot detects another robot with a high level of social need, the behavior turns into \n",
    "attraction, and when the robot detects a robot with a low level of social need, the behavior turns into \n",
    "repulsion:\n",
    "\n",
    "    - If the sensor X (being X \"left\" or \"right\") detects a robot with a high level of social need, \n",
    "    the X_activation value decreases, so the X wheel velocity decreases, and it turns into an \n",
    "    attraction behavior towards this detected robot.\n",
    "    \n",
    "    - In the same way, if the sensor X (being X \"left\" or \"right\") detects a robot with a low level \n",
    "    of social need, the X_activation value increases, so the X wheel velocity increases, and it turns \n",
    "    into a repulsion behavior towards this detected robot.\n",
    "'''\n",
    "\n",
    "def epuck_attraction_repulsion_social(robot):\n",
    "    left, right = robot.prox_activations(tracked_objects=[\"ePuck\"])\n",
    "    (left, right), (epuck_left, epuck_right) = robot.prox_activations(tracked_objects=[\"ePuck\"], return_epucks=True)\n",
    "    left_social, right_social = robot.sensed_epuck_attributes(epuck_left, epuck_right, \"social_need\", default_value=0)\n",
    "    \n",
    "    left_activation = 1 - left_social\n",
    "    right_activation = 1 - right_social\n",
    "    \n",
    "    return left_activation, right_activation\n",
    "\n",
    "\n",
    "simulator.start_sphere_apparition(period=5)\n",
    "for e in simulator.robots: \n",
    "    e.detach_all_behaviors()\n",
    "    e.attach_routine(foraging_drive, freq=1)\n",
    "    e.attach_routine(social_drive, freq=1)\n",
    "    e.energy_level = 0.5\n",
    "    e.social_need = 0.5\n",
    "    e.start_routine(foraging_drive)\n",
    "    e.start_routine(social_drive)\n",
    "    e.attach_behavior(obstacle_avoidance, freq=10)\n",
    "    e.attach_behavior(foraging, freq=10)\n",
    "    e.attach_behavior(epuck_attraction_repulsion_social, freq=10)\n",
    "    e.start_all_behaviors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "close_session(simulator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## About the mini-project\n",
    "\n",
    "The aim of the mini project is to show that you have understood all the concepts we have seen during these three practical sessions and that you can integrate them in a single demo. You can of course modify the V-REP scene at your will, e.g adding cups or trees. Don't forget to save you modified V-REP scene (`File -> Save scene as` in V-REP). You can start your project in a new Jupyter Notebook (`File -> New notebook -> Python3`) in the menu bar at the top of this notebook). Use both text cells (explaining what you are doing) and code cells (with the corresponding code to execute).\n",
    "\n",
    "Therefore, your project will consists of two files: a V-REP scene (extension `.ttt`) a Jupyter Notebook (extension `.ipynb`). Don't forget to save them, e.g. on a USB stick, before logging out from the UPF computers. See [this slide](https://docs.google.com/presentation/d/1FlAUyvNynYU4mDBE2o20pf2Bn5PC_9Id3SK8sCMfr-Q/edit#slide=id.g34900c6ead_0_0) for more information on the mini-project."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
